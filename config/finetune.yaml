name: finetune-halle
data:
  rasters: /work/ka1176/shared_data/2024-ufz-deeptree/polygon-labelling/tiles  # directory with raster images
  masks: /work/ka1176/shared_data/2024-ufz-deeptree/polygon-labelling/tiles    # directory with masks
  outlines: /work/ka1176/shared_data/2024-ufz-deeptree/polygon-labelling/tiles # directory with outlines
  dist: /work/ka1176/shared_data/2024-ufz-deeptree/polygon-labelling/tiles     # directory with distance transforms
  width: 256             # Width and height of the cropped images returned by the data loader
  batchsize: 32          # dataloader batch size
  training_split: 0.8    # Train/val split
  concatenate_ndvi: True # If True, concatenate NDVI
  red: 0                 # Index of Red channel
  nir: 3                 # Index of Infrared channel
model:
  model_name: unet-halle # short and memorable model name
  arch: Unet-resnet18    # model architecture
  in_channels: 5         # Number of input channels / bands of the input image
  lr: 0.0003             # learning rate
  pretrained_model: null # pretrained model checkpoint (null: train from scratch)
logdir: ${hydra.run.dir} # this is where we find logs, trained models, predictions
model_save_path: null # TODO

trainer:
  _target_: lightning.Trainer
  devices: 1               # Number of devices (GPUs) to use
  accelerator: auto        # Choose GPU if available
  max_epochs: 100          # maximum number of epochs
  num_sanity_val_steps: 1  # sanity check before training starts
  fast_dev_run: False      # if True, runs one batch of each dataloader

hydra:
  job:
    chdir: True
  run:
    dir: experiments/${hydra.job.name}/${now:%Y-%m-%d}_${now:%H-%M-%S}
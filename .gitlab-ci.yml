stages:
  - test
  - release
  - docs
  - build
  - publish
  - joss


run_tests:
  image: continuumio/miniconda3:latest
  stage: test
  before_script:
    - apt-get update && apt-get install -y wget curl unzip
    - wget -q -O polygon-labelling.zip "https://nextcloud.dkrz.de/index.php/s/xdcT8GLikHs4Xps/download"
    - unzip polygon-labelling.zip -d ./polygon-labelling
    - conda init bash
    - source ~/.bashrc
    - conda config --add channels conda-forge
    - conda config --set channel_priority strict
    - conda install -n base --override-channels -c conda-forge sqlite -y  # Install SQLite first
    - conda install -n base --override-channels -c conda-forge python -y  # Ensure Python from conda-forge
    - conda run -n base python --version  # Verify Python version
    - conda install -n base --override-channels -c conda-forge gdal=3.9.2
    - conda install -n base --override-channels -c conda-forge numpy -y  # GDAL often depends on numpy
    - conda run -n base python -m pip install --upgrade pip  # Use conda run to upgrade pip
    - conda run -n base pip install -r requirements.txt  # Use conda run to install requirements
    
  script:
    - conda run -n base python -c "from osgeo import gdal; print('GDAL imported successfully')"   
    - conda run -n base python -m scripts.test --config-dir=./config/CD/ --config-name=cd_test data.ground_truth_config.labels=null +trainer.fast_dev_run=True output_dir=test_suite
    - conda run -n base python -m scripts.train --config-dir=./config/CD --config-name=cd_train trainer.fast_dev_run=True output_dir=test_suite
    - conda run -n base python -m scripts.train --config-dir=./config/CD --config-name=cd_finetune data.ground_truth_config.labels=null trainer.fast_dev_run=True output_dir=test_suite
    - conda run -n base python -m deeptrees.inference --config_path=./config/CD/predict/inference_on_individual_tiles.yaml --image_path=/builds/taimur.khan/DeepTrees/polygon-labelling/polygon-labelling/pool_tiles/tile_8_15.tif 

  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    - if: '$CI_COMMIT_BRANCH == "main"'

  allow_failure: false


semantic-versioning:
  image: node:lts
  stage: release
  variables:
    GITLAB_TOKEN: $GITLAB_TOKEN_SEMANTIC_VERSIONING
  script:
    - npx -y
      -p @semantic-release/commit-analyzer@9.0.2
      -p @semantic-release/git@10.0.1
      -p @semantic-release/gitlab@9.5.0
      -p @semantic-release/release-notes-generator@10.0.3
      -p @semantic-release/exec@6.0.3
      -p @semantic-release/changelog@6.0.2
      -p conventional-changelog-conventionalcommits@5.0.0
      -p semantic-release@19.0.5
      semantic-release
  dependencies:
    - run_tests
  only:
    - main

pages:
  image: python:3.10
  stage: docs
  before_script:
    - python -m pip install --upgrade pip
    - pip3 install sphinx sphinx-rtd-theme sphinx_autodoc_typehints
  script:
    - cp -r docs/build/html public/
  artifacts:
    paths:
      - public/
  dependencies:
    - run_tests
  only:
    - main

readthedocs:
  image: alpine:latest
  stage: docs
  before_script:
    - apk add curl
  script:
    - 'curl -X POST -H "Authorization: Token $RTD_TOKEN" https://readthedocs.org/api/v3/projects/deeptrees/versions/latest/builds/'
  rules:
    # Only run the job on the default branch and not in forks.
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH && $CI_PROJECT_PATH == "taimur.khan/DeepTrees"
  dependencies:
    - run_tests

build-package:
  image: python:3.10
  stage: build
  before_script:
    - python -m pip install --upgrade pip
    - pip install setuptools wheel
  script:
    - python setup.py sdist bdist_wheel
  artifacts:
    paths:
      - dist/
  rules:
    - if: $CI_COMMIT_TAG =~ /^v\d+\.\d+\.\d+$/
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH && $CI_PROJECT_PATH == "taimur.khan/DeepTrees"
  dependencies:
    - semantic-versioning


gitlab-publish:
  image: python:3.10
  stage: publish
  before_script:
    - python -m pip install --upgrade pip
    - pip install setuptools wheel twine
  script:
    - TWINE_PASSWORD=${CI_JOB_TOKEN} TWINE_USERNAME=gitlab-ci-token python -m twine upload --repository-url ${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/packages/pypi dist/*
  rules:
    - if: $CI_COMMIT_TAG =~ /^v\d+\.\d+\.\d+$/
  dependencies:
    - build-package

pypi-publish:
  image: python:3.10
  stage: publish
  before_script:
    - python -m pip install --upgrade pip
    - pip install setuptools wheel twine
  script:
    - TWINE_PASSWORD=${PYPI_TOKEN} TWINE_USERNAME=__token__ python -m twine upload dist/*
  rules:
    - if: $CI_COMMIT_TAG =~ /^v\d+\.\d+\.\d+$/
  dependencies:
    - build-package

joss-inara:
  stage: joss
  image:
    name: openjournals/inara
    entrypoint: ["/bin/sh", "-c"]
  variables:
    GIT_SHA: $CI_COMMIT_SHA
    JOURNAL: joss
  script:
    - inara -o pdf,cff ./docs/joss/paper.md
  rules:
    - if: '$CI_COMMIT_BRANCH == "joss"'
      when: always
    - when: never
  allow_failure: false
  artifacts:
    paths:
  needs: []


 
